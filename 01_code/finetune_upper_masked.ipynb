{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Qm_5cG5Vph14","executionInfo":{"status":"ok","timestamp":1713484870480,"user_tz":240,"elapsed":7236,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}}},"outputs":[],"source":["import torchvision.models as models\n","import torch.nn as nn\n","import torch\n","import loaders\n","import hyperparameters\n","import training"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IiapzQgph18","executionInfo":{"status":"ok","timestamp":1713486134142,"user_tz":240,"elapsed":691,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}},"outputId":"1e6a909f-5e21-403c-9a91-328628e3f2ac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":15}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","## setup current model and load weights\n","resnet50 = models.resnet50()\n","num_classes = 7\n","resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n","pretrained = torch.load(\"./saved_model/resnet50_on_FER.pth\")\n","resnet50.load_state_dict(pretrained[\"state_dict\"])\n","resnet50.to(device)\n","resnet50.eval()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"1URTLI-Hph19","executionInfo":{"status":"ok","timestamp":1713486136498,"user_tz":240,"elapsed":4,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}}},"outputs":[],"source":["## make some evaluation on full image (no mask)\n","full_val_loader = loaders.get_loader(\n","    mask=\"full\", train=False\n",")\n","# VAL_BATCH_SIZE = 100\n","# full_val_transform = transforms.Compose(\n","#     [\n","#         transforms.ToTensor(),\n","#         transforms.Normalize(\n","#             (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n","#         )\n","#     ]\n","# )\n","# full_val_set = FacialImageData(\n","#     directory=\"./data/test\",\n","#     transform=full_val_transform\n","# )\n","# full_val_loader = DataLoader(\n","#     full_val_set,\n","#     batch_size=VAL_BATCH_SIZE,\n","#     shuffle=False,\n","#     num_workers=2\n","# )"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pH1XR9-6ph1-","executionInfo":{"status":"ok","timestamp":1713485029247,"user_tz":240,"elapsed":115,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}}},"outputs":[],"source":["loss_func = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yi87VNqYph1-","executionInfo":{"status":"ok","timestamp":1713485036568,"user_tz":240,"elapsed":6571,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}},"outputId":"9bbcc233-91c9-4688-b070-68dc92a41c70"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 0.9739, Validation accuracy: 0.6649\n"]}],"source":["with torch.no_grad():\n","    val_loss = 0\n","    total_examples = 0\n","    correct_examples = 0\n","    for batch_idx, (inputs, targets) in enumerate(full_val_loader):\n","        # copy inputs to device\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        # compute the output and loss\n","        out = resnet50(inputs)\n","        loss = loss_func(out, targets)\n","        # count the number of correctly predicted samples\n","        # in the current batch\n","        _, predicted = torch.max(out, 1)\n","        correct = predicted.eq(targets).sum()\n","        val_loss += loss.detach().cpu()\n","        total_examples += targets.shape[0]\n","        correct_examples += correct.item()\n","avg_loss = val_loss / len(full_val_loader)\n","avg_acc = correct_examples / total_examples\n","print(\n","    \"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc)\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Vj82j3BDph1-","executionInfo":{"status":"ok","timestamp":1713485038877,"user_tz":240,"elapsed":133,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}}},"outputs":[],"source":["## make some evaluation on upper masked image (upper mask)\n","upper_mask_val_loader = loaders.get_loader(\n","    mask=\"upper\", train=False\n",")\n","# upper_mask_val_transform = transforms.Compose(\n","#     [\n","#         transforms.ToTensor(),\n","#         ImgMask([1, 2]),\n","#         transforms.Normalize(\n","#             (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n","#         )\n","#     ]\n","# )\n","# upper_mask_val_set = FacialImageData(\n","#     directory=\"./data/test\",\n","#     transform=upper_mask_val_transform\n","# )\n","# upper_mask_val_loader = DataLoader(\n","#     upper_mask_val_set,\n","#     batch_size=VAL_BATCH_SIZE,\n","#     shuffle=False,\n","#     num_workers=2\n","# )"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oIOOerK-ph1_","executionInfo":{"status":"ok","timestamp":1713485044897,"user_tz":240,"elapsed":4227,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}},"outputId":"1b51d5ce-6ef9-4602-8724-8b871f293236"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation loss: 1.9198, Validation accuracy: 0.4489\n"]}],"source":["with torch.no_grad():\n","    val_loss = 0\n","    total_examples = 0\n","    correct_examples = 0\n","    for batch_idx, (inputs, targets) in enumerate(upper_mask_val_loader):\n","        # copy inputs to device\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        # compute the output and loss\n","        out = resnet50(inputs)\n","        loss = loss_func(out, targets)\n","        # count the number of correctly predicted samples\n","        # in the current batch\n","        _, predicted = torch.max(out, 1)\n","        correct = predicted.eq(targets).sum()\n","        val_loss += loss.detach().cpu()\n","        total_examples += targets.shape[0]\n","        correct_examples += correct.item()\n","avg_loss = val_loss / len(upper_mask_val_loader)\n","avg_acc = correct_examples / total_examples\n","print(\n","    \"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8VSasqTph2A"},"outputs":[],"source":["## further fine tune the model\n","## define hyperparameters\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"U2J9j8dWph2A","executionInfo":{"status":"ok","timestamp":1713485046978,"user_tz":240,"elapsed":274,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}}},"outputs":[],"source":["## trainning data\n","upper_mask_train_loader = loaders.get_loader(\n","    mask=\"upper\", train=True\n",")\n","# TRAIN_BATCH_SIZE = 128\n","# upper_mask_train_transform = transforms.Compose(\n","#     [\n","#         # transforms.RandomCrop(48, padding=4),\n","#         # transforms.RandomHorizontalFlip(),\n","#         transforms.ToTensor(),\n","#         ImgMask([1, 2]),\n","#         transforms.Normalize(\n","#             (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n","#         )\n","#     ]\n","# )\n","# upper_mask_train_set = FacialImageData(\n","#     directory=\"./data/test\",\n","#     transform=upper_mask_train_transform\n","# )\n","# upper_mask_train_loader = DataLoader(\n","#     upper_mask_train_set,\n","#     batch_size=TRAIN_BATCH_SIZE,\n","#     shuffle=True,\n","#     num_workers=2\n","# )"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6dXc8Oywph2A","executionInfo":{"status":"ok","timestamp":1713486652482,"user_tz":240,"elapsed":510567,"user":{"displayName":"Guangzheng Li","userId":"05483222487431288259"}},"outputId":"3d080970-01e0-490a-f016-7dd9c97ca82f"},"outputs":[{"output_type":"stream","name":"stdout","text":["==> Training starts!\n","==================================================\n","Epoch 0:\n","Training loss: 1.1685, Training accuracy: 0.5575\n","Validation loss: 1.1629, Validation accuracy: 0.5589\n","Saving ...\n","\n","Validation loss: 1.0666, Validation accuracy: 0.6089\n","Epoch 1:\n","Training loss: 0.9843, Training accuracy: 0.6305\n","Validation loss: 1.1577, Validation accuracy: 0.5685\n","Saving ...\n","\n","Validation loss: 1.1056, Validation accuracy: 0.5858\n","Epoch 2:\n","Training loss: 0.8511, Training accuracy: 0.6846\n","Validation loss: 1.2144, Validation accuracy: 0.5662\n","\n","Validation loss: 1.1866, Validation accuracy: 0.5908\n","Epoch 3:\n","Training loss: 0.7400, Training accuracy: 0.7278\n","Validation loss: 1.3535, Validation accuracy: 0.5495\n","\n","Validation loss: 1.3631, Validation accuracy: 0.5762\n","Epoch 4:\n","Training loss: 0.6459, Training accuracy: 0.7624\n","Validation loss: 1.3194, Validation accuracy: 0.5701\n","Saving ...\n","\n","Validation loss: 1.2578, Validation accuracy: 0.5933\n","Epoch 5:\n","Training loss: 0.5452, Training accuracy: 0.8013\n","Validation loss: 1.3840, Validation accuracy: 0.5690\n","\n","Validation loss: 1.4232, Validation accuracy: 0.5712\n","Current learning rate has decayed to 0.001000\n","Epoch 6:\n","Training loss: 0.2486, Training accuracy: 0.9179\n","Validation loss: 1.5688, Validation accuracy: 0.6082\n","Saving ...\n","\n","Validation loss: 1.5413, Validation accuracy: 0.6109\n","Epoch 7:\n","Training loss: 0.1083, Training accuracy: 0.9677\n","Validation loss: 1.8808, Validation accuracy: 0.6042\n","\n","Validation loss: 1.6923, Validation accuracy: 0.6123\n","Epoch 8:\n","Training loss: 0.0580, Training accuracy: 0.9835\n","Validation loss: 2.1559, Validation accuracy: 0.6080\n","\n","Validation loss: 1.8867, Validation accuracy: 0.6094\n","Epoch 9:\n","Training loss: 0.0346, Training accuracy: 0.9908\n","Validation loss: 2.5070, Validation accuracy: 0.6024\n","\n","Validation loss: 2.0251, Validation accuracy: 0.6096\n","Epoch 10:\n","Training loss: 0.0235, Training accuracy: 0.9940\n","Validation loss: 2.6150, Validation accuracy: 0.6011\n","\n","Validation loss: 2.1275, Validation accuracy: 0.6069\n","Current learning rate has decayed to 0.000100\n","Epoch 11:\n","Training loss: 0.0159, Training accuracy: 0.9961\n","Validation loss: 2.7202, Validation accuracy: 0.6028\n","\n","Validation loss: 2.1655, Validation accuracy: 0.6103\n","Epoch 12:\n","Training loss: 0.0154, Training accuracy: 0.9961\n","Validation loss: 2.7524, Validation accuracy: 0.5999\n","\n","Validation loss: 2.1636, Validation accuracy: 0.6074\n","Epoch 13:\n","Training loss: 0.0132, Training accuracy: 0.9962\n","Validation loss: 2.7943, Validation accuracy: 0.6060\n","\n","Validation loss: 2.1997, Validation accuracy: 0.6082\n","Epoch 14:\n","Training loss: 0.0117, Training accuracy: 0.9972\n","Validation loss: 2.7682, Validation accuracy: 0.6018\n","\n","Validation loss: 2.2202, Validation accuracy: 0.6085\n","==================================================\n","==> Optimization finished! Best validation accuracy: 0.6082\n"]},{"output_type":"execute_result","data":{"text/plain":["([0.5575255146469749,\n","  0.6304991466090772,\n","  0.6846285137065032,\n","  0.7277508795151346,\n","  0.7624438329443728,\n","  0.8012818279981887,\n","  0.9179351422898743,\n","  0.9677104740673657,\n","  0.9834894980668083,\n","  0.9908391096868577,\n","  0.9940088473997701,\n","  0.9960639520707792,\n","  0.9960987843533387,\n","  0.9961684489184576,\n","  0.9972134173952419],\n"," [tensor(1.1685),\n","  tensor(0.9843),\n","  tensor(0.8511),\n","  tensor(0.7400),\n","  tensor(0.6459),\n","  tensor(0.5452),\n","  tensor(0.2486),\n","  tensor(0.1083),\n","  tensor(0.0580),\n","  tensor(0.0346),\n","  tensor(0.0235),\n","  tensor(0.0159),\n","  tensor(0.0154),\n","  tensor(0.0132),\n","  tensor(0.0117)],\n"," [0.5589300640847032,\n","  0.5685427695736974,\n","  0.5661744218445249,\n","  0.5494566731680134,\n","  0.5700752298690444,\n","  0.5689607132906102,\n","  0.6082474226804123,\n","  0.6042073000835887,\n","  0.6079687935358038,\n","  0.6023962106436334,\n","  0.601142379492895,\n","  0.6028141543605461,\n","  0.5998885483421565,\n","  0.6060183895235441,\n","  0.6018389523544163],\n"," [tensor(1.1629),\n","  tensor(1.1577),\n","  tensor(1.2144),\n","  tensor(1.3535),\n","  tensor(1.3194),\n","  tensor(1.3840),\n","  tensor(1.5688),\n","  tensor(1.8808),\n","  tensor(2.1559),\n","  tensor(2.5070),\n","  tensor(2.6150),\n","  tensor(2.7202),\n","  tensor(2.7524),\n","  tensor(2.7943),\n","  tensor(2.7682)],\n"," [0.6089439955419337,\n","  0.585817776539426,\n","  0.5908331011423795,\n","  0.5762050710504318,\n","  0.5933407634438562,\n","  0.5711897464474784,\n","  0.6108943995541933,\n","  0.612287545277236,\n","  0.6093619392588465,\n","  0.609640568403455,\n","  0.6068542769573697,\n","  0.6103371412649763,\n","  0.6074115352465868,\n","  0.6082474226804123,\n","  0.6085260518250208],\n"," [tensor(1.0666),\n","  tensor(1.1056),\n","  tensor(1.1866),\n","  tensor(1.3631),\n","  tensor(1.2578),\n","  tensor(1.4232),\n","  tensor(1.5413),\n","  tensor(1.6923),\n","  tensor(1.8867),\n","  tensor(2.0251),\n","  tensor(2.1275),\n","  tensor(2.1655),\n","  tensor(2.1636),\n","  tensor(2.1997),\n","  tensor(2.2202)])"]},"metadata":{},"execution_count":17}],"source":["training.train_model(\n","    resnet50,\n","    device,\n","    hyperparameters.CHECKPOINT_FOLDER,\n","    \"upper.pth\",\n","    hyperparameters.LR,\n","    hyperparameters.MOMENTUM,\n","    hyperparameters.REG,\n","    15,\n","    upper_mask_train_loader,\n","    upper_mask_val_loader,\n","    loss_func,\n","    full_val_loader,\n","    0.1,\n","    5\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TuXZXzFGph2B"},"outputs":[],"source":["# ## create optimizer\n","# optimizer = optim.SGD(\n","#     resnet50.parameters(),\n","#     lr=hyperparameters.LR,\n","#     momentum=hyperparameters.MOMENTUM,\n","#     weight_decay=hyperparameters.REG\n","# )\n","\n","# # the folder where the trained model is saved\n","# CHECKPOINT_FOLDER = \"./saved_model\"\n","# best_val_acc = 0\n","# resnet50 = resnet50.to(device)\n","# current_learning_rate = hyperparameters.LR\n","\n","\n","# train_loss_hist = []\n","# train_acc_hist = []\n","# test_loss_hist = []\n","# test_acc_hist = []\n","# # start the training/validation process\n","# print(\"==> Training starts!\")\n","# print(\"=\"*50)\n","# for i in range(0, hyperparameters.NUM_EPOCH):\n","#     print(\"Epoch %d:\" %i)\n","#     ## Train on the train set\n","#     #####################################################################\n","#     # switch to train mode\n","#     resnet50.train()\n","#     # this help you compute the training accuracy\n","#     total_examples = 0\n","#     correct_examples = 0\n","#     train_loss = 0 # track training loss if you want\n","#     # Train the model for 1 epoch.\n","#     for batch_idx, (inputs, targets) in enumerate(upper_mask_train_loader):\n","#         # copy inputs to device\n","#         inputs = inputs.to(device)\n","#         targets = targets.to(device)\n","#         # compute the output and loss\n","#         out = resnet50(inputs)\n","#         loss = loss_func(out, targets)\n","#         # zero the gradient\n","#         optimizer.zero_grad()\n","#         # backpropagation\n","#         loss.backward()\n","#         # apply gradient and update the weights\n","#         optimizer.step()\n","#         # count the number of correctly predicted samples in the current batch\n","#         _, predicted = torch.max(out, 1)\n","#         correct = predicted.eq(targets).sum()\n","#         train_loss += loss.detach().cpu()\n","#         total_examples += targets.shape[0]\n","#         correct_examples += correct.item()\n","#     avg_loss = train_loss / len(upper_mask_train_loader)\n","#     train_loss_hist.append(avg_loss)\n","#     avg_acc = correct_examples / total_examples\n","#     train_acc_hist.append(avg_acc)\n","#     print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n","#     ######################################################################\n","\n","#     # Validate on the validation dataset (masked)\n","#     ######################################################################\n","#     # switch to eval mode\n","#     resnet50.eval()\n","#     # this help you compute the validation accuracy\n","#     total_examples = 0\n","#     correct_examples = 0\n","#     val_loss = 0 # track the validation loss\n","#     # disable gradient during validation, which can save GPU memory\n","#     with torch.no_grad():\n","#         for batch_idx, (inputs, targets) in enumerate(upper_mask_val_loader):\n","#             # copy inputs to device\n","#             inputs = inputs.to(device)\n","#             targets = targets.to(device)\n","#             # compute the output and loss\n","#             out = resnet50(inputs)\n","#             loss = loss_func(out, targets)\n","#             # count the number of correctly predicted samples\n","#             # in the current batch\n","#             _, predicted = torch.max(out, 1)\n","#             correct = predicted.eq(targets).sum()\n","#             val_loss += loss.detach().cpu()\n","#             total_examples += targets.shape[0]\n","#             correct_examples += correct.item()\n","#     avg_loss = val_loss / len(upper_mask_val_loader)\n","#     test_loss_hist.append(avg_loss)\n","#     avg_acc = correct_examples / total_examples\n","#     test_acc_hist.append(avg_acc)\n","#     print(\n","#         \"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc)\n","#     )\n","#     ######################################################################\n","\n","#     # save the model checkpoint\n","#     if avg_acc > best_val_acc:\n","#         best_val_acc = avg_acc\n","#         if not os.path.exists(CHECKPOINT_FOLDER):\n","#            os.makedirs(CHECKPOINT_FOLDER)\n","#         print(\"Saving ...\")\n","#         state = {'state_dict': resnet50.state_dict(),\n","#                 'epoch': i,\n","#                 'lr': current_learning_rate}\n","#         torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'resnet50_on_upper_masked.pth'))\n","#     print('')\n","#     ## decay learning rate\n","#     # if i % DECAY_EPOCH == 0 and i != 0:\n","#     #     current_learning_rate *= LR_DECAY\n","#     #     for param_group in optimizer.param_groups:\n","#     #         param_group[\"lr\"] = current_learning_rate\n","#     #         print(f\"Current learning rate has decayed to %f\" %current_learning_rate)\n","\n","# print(\"=\"*50)\n","# print(\n","#     f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\"\n","# )"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}