{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import loaders\n",
    "import hyperparameters\n",
    "import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "## setup current model and load weights\n",
    "resnet50 = models.resnet50()\n",
    "num_classes = 7\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "pretrained = torch.load(\"./saved_model/resnet50_on_FER.pth\")\n",
    "resnet50.load_state_dict(pretrained[\"state_dict\"])\n",
    "resnet50.to(device)\n",
    "resnet50.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate on full face\n",
    "full_val_loader = loaders.get_loader(\n",
    "    mask=\"full\", train=False, shuffle=False\n",
    ")\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(full_val_loader):\n",
    "        # copy inputs to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # compute the output and loss\n",
    "        out = resnet50(inputs)\n",
    "        loss = loss_func(out, targets)\n",
    "        # count the number of correctly predicted samples\n",
    "        # in the current batch\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        correct = predicted.eq(targets).sum()\n",
    "        val_loss += loss.detach().cpu()\n",
    "        total_examples += targets.shape[0]\n",
    "        correct_examples += correct.item()\n",
    "avg_loss = val_loss / len(full_val_loader)\n",
    "avg_acc = correct_examples / total_examples\n",
    "print(\n",
    "    \"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate on lower face\n",
    "lower_mask_val_loader = loaders.get_loader(\n",
    "    mask=\"lower\", train=False, shuffle=False\n",
    ")\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(lower_mask_val_loader):\n",
    "        # copy inputs to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # compute the output and loss\n",
    "        out = resnet50(inputs)\n",
    "        loss = loss_func(out, targets)\n",
    "        # count the number of correctly predicted samples\n",
    "        # in the current batch\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        correct = predicted.eq(targets).sum()\n",
    "        val_loss += loss.detach().cpu()\n",
    "        total_examples += targets.shape[0]\n",
    "        correct_examples += correct.item()\n",
    "avg_loss = val_loss / len(lower_mask_val_loader)\n",
    "avg_acc = correct_examples / total_examples\n",
    "print(\n",
    "    \"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_mask_train_loader = loaders.get_loader(\n",
    "    mask=\"lower\", train=True, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.train_model(\n",
    "    resnet50,\n",
    "    device,\n",
    "    hyperparameters.CHECKPOINT_FOLDER,\n",
    "    \"lower.pth\",\n",
    "    hyperparameters.LR,\n",
    "    hyperparameters.MOMENTUM,\n",
    "    hyperparameters.REG,\n",
    "    15,\n",
    "    lower_mask_train_loader,\n",
    "    lower_mask_val_loader,\n",
    "    loss_func,\n",
    "    full_val_loader,\n",
    "    0.1,\n",
    "    5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
